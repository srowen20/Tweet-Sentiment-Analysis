{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b5ec09a-702d-4cee-8d73-fc478a5258a3",
   "metadata": {},
   "source": [
    "# VertexAI Sentiment Analysis Notebook\n",
    "\n",
    "Date of creation: Jan 23\n",
    "\n",
    "In this notebook you will find a sentiment analysis pipeline created in VertexAI.\n",
    "\n",
    "The pipeline:\n",
    "- Starts from a csv file which has been stored in gcs \n",
    "- Creates a VertexAI dataset from the data \n",
    "- Creates a sentiment analysis model classifying Negative Neutral and Positive sentiments \n",
    "- Fetches model evaluation metrics and confusion matrix\n",
    "- Saves metrics, confusion matrix and gcs file to BigQuery\n",
    "\n",
    "Documentation links:\n",
    "1. Creating service account key, this is used to create a json file which was saved to the VM \n",
    "    - https://cloud.google.com/iam/docs/creating-managing-service-account-keys#iam-service-account-keys-create-console\n",
    "    \n",
    "2. Overview of modelling in vertex AI using the api with coded examples with short video intros. Here is where you can find almost all the functions in this notebook under the section describing sentiment analysis for text data.\n",
    "    - https://cloud.google.com/vertex-ai/docs/training-overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bae54c0-6a6d-4741-ba76-68edeb58e1e3",
   "metadata": {},
   "source": [
    "## Imports, Variables & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb87ade-5351-4860-97f9-0f7bbf275866",
   "metadata": {},
   "outputs": [],
   "source": [
    "### List of imports\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from itertools import islice\n",
    "import google\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "import os\n",
    "import time\n",
    "import calendar\n",
    "import json\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0529c16-643f-4051-9cc1-8f96a42ab9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### List of variables required for functions\n",
    "\n",
    "#Credentials for google api, points to json key which was manually loaded to instance\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'ab-mlai-team-dev-5bb89ad0ff4c.json'\n",
    "\n",
    "#Variables for dataset creation\n",
    "gcp_project = 'ab-mlai-team-dev'\n",
    "location = 'europe-west4'\n",
    "gcs_source = 'gs://mlai-nlp/cleaned_data/cleaned_600_elements.csv'\n",
    "bq_dataset = 'Corona_NLP'\n",
    "\n",
    "#Creating unique filename\n",
    "current_GMT = time.gmtime()\n",
    "ts = calendar.timegm(current_GMT)\n",
    "filename = gcs_source.split('/')[-1].rstrip('.csv') + str(ts)\n",
    "todays_date = date.today().strftime(\"%d-%m-%Y\")\n",
    "\n",
    "#Import schema\n",
    "import_schema_uri = aiplatform.schema.dataset.ioformat.text.sentiment\n",
    "\n",
    "#Variables for training pipeline creation\n",
    "dataset_id = 'projects/526415775648/locations/europe-west4/datasets/4244609663447859200'\n",
    "model_display_name = dataset_id.split('/')[-1]\n",
    "sentiment_max = 2\n",
    "\n",
    "#Variables for model evaluation\n",
    "model_id = '2508971185375543296'\n",
    "model_parent = f'projects/{gcp_project}/locations/{location}/models/{model_id}'\n",
    "\n",
    "#Variables for batch predictions\n",
    "inference_dataset_source = 'gs://mlai-nlp/cleaned_data/inference_dataset.csv' \n",
    "inference_bucket = 'nlp-batch-prediction-test'\n",
    "source_bucket = 'mlai-nlp'\n",
    "\n",
    "#Notebook controls\n",
    "create_dataset =  False\n",
    "create_model = False\n",
    "load_gcs_source_to_bq = False\n",
    "load_evals_to_bq = False\n",
    "load_confusion_matrix_to_bq = False\n",
    "preform_batch_prediction = False\n",
    "load_batch_prediction_to_bq = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846e1d4e-4e32-48c6-aadf-cafeda8f8801",
   "metadata": {},
   "outputs": [],
   "source": [
    "todays_date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf597f9-783e-405d-a39f-debe15e8d1ca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961eeccc-603f-4df6-b902-a385db26d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Functions\n",
    "\n",
    "def create_and_import_text_dataset_from_bigquery(\n",
    "    display_name: str,\n",
    "    project: str,\n",
    "    location: str,\n",
    "    gcs_source: str\n",
    "):\n",
    "\n",
    "    aiplatform.init(project=project, location=location)\n",
    "    \n",
    "    #change dataset type here if not using tabular data:\n",
    "    dataset = aiplatform.TextDataset.create(\n",
    "        display_name=display_name,\n",
    "        project = gcp_project,\n",
    "        location = location,\n",
    "        gcs_source=gcs_source,\n",
    "        import_schema_uri=import_schema_uri\n",
    "    )\n",
    "\n",
    "    dataset.wait()\n",
    "\n",
    "    print(f'\\tDataset: \"{dataset.display_name}\"')\n",
    "    print(f'\\tname: \"{dataset.resource_name}\"')\n",
    "    \n",
    "    return dataset.resource_name\n",
    "\n",
    "def create_training_pipeline_text_sentiment_analysis_sample(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    display_name: str,\n",
    "    dataset_id: str,\n",
    "    model_display_name: str,\n",
    "    sentiment_max: int = 2,\n",
    "):\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    job = aiplatform.AutoMLTextTrainingJob(\n",
    "        display_name=display_name,\n",
    "        prediction_type=\"sentiment\",\n",
    "        sentiment_max=sentiment_max,\n",
    "    )\n",
    "\n",
    "    text_dataset = aiplatform.TextDataset(dataset_id)\n",
    "\n",
    "    model = job.run(\n",
    "        dataset=text_dataset,\n",
    "        model_display_name=model_display_name,\n",
    "        training_filter_split=\"labels.aiplatform.googleapis.com/ml_use=training\",\n",
    "        validation_filter_split=\"labels.aiplatform.googleapis.com/ml_use=validation\",\n",
    "        test_filter_split=\"labels.aiplatform.googleapis.com/ml_use=test\",\n",
    "    )\n",
    "\n",
    "    model.wait()\n",
    "\n",
    "    print(model.display_name)\n",
    "    print(model.resource_name)\n",
    "    print(model.uri)\n",
    "    return model\n",
    "\n",
    "def get_model_evaluation_text_sentiment_analysis_sample(\n",
    "    project: str,\n",
    "    model_id: str,\n",
    "    evaluation_id: str,\n",
    "    location: str,\n",
    "    api_endpoint: str = f\"{location}-aiplatform.googleapis.com\",\n",
    "):\n",
    "    \"\"\"\n",
    "    To obtain evaluation_id run the following commands where LOCATION\n",
    "    is the region where the model is stored, PROJECT is the project ID,\n",
    "    and MODEL_ID is the ID of your model.\n",
    "\n",
    "    model_client = aiplatform.gapic.ModelServiceClient(\n",
    "        client_options={\n",
    "            'api_endpoint':'LOCATION-aiplatform.googleapis.com'\n",
    "            }\n",
    "        )\n",
    "    evaluations = model_client.list_model_evaluations(parent='projects/PROJECT/locations/LOCATION/models/MODEL_ID')\n",
    "    print(\"evaluations:\", evaluations)\n",
    "    \"\"\"\n",
    "    # The AI Platform services require regional API endpoints.\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    # This client only needs to be created once, and can be reused for multiple requests.\n",
    "    client = aiplatform.gapic.ModelServiceClient(client_options=client_options)\n",
    "    name = client.model_evaluation_path(\n",
    "        project=project, location=location, model=model_id, evaluation=evaluation_id\n",
    "    )\n",
    "    response = client.get_model_evaluation(name=name)\n",
    "    print(\"response:\", response)\n",
    "\n",
    "def get_model_evaluation_slice_sample(\n",
    "    project: str,\n",
    "    model_id: str,\n",
    "    evaluation_id: str,\n",
    "    slice_id: str,\n",
    "    location: str,\n",
    "    api_endpoint: str = f\"{location}-aiplatform.googleapis.com\",\n",
    "):\n",
    "    \"\"\"\n",
    "    To obtain evaluation_id run the following commands where LOCATION\n",
    "    is the region where the model is stored, PROJECT is the project ID,\n",
    "    and MODEL_ID is the ID of your model.\n",
    "\n",
    "    model_client = aiplatform.gapic.ModelServiceClient(\n",
    "        client_options={\n",
    "            'api_endpoint':'LOCATION-aiplatform.googleapis.com'\n",
    "            }\n",
    "        )\n",
    "    evaluations = model_client.list_model_evaluations(parent='projects/PROJECT/locations/LOCATION/models/MODEL_ID')\n",
    "    print(\"evaluations:\", evaluations)\n",
    "    \"\"\"\n",
    "    # The AI Platform services require regional API endpoints.\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    # This client only needs to be created once, and can be reused for multiple requests.\n",
    "    client = aiplatform.gapic.ModelServiceClient(client_options=client_options)\n",
    "    name = client.model_evaluation_slice_path(\n",
    "        project=project,\n",
    "        location=location,\n",
    "        model=model_id,\n",
    "        evaluation=evaluation_id,\n",
    "        slice=slice_id,\n",
    "    )\n",
    "    response = client.get_model_evaluation_slice(name=name)\n",
    "    print(\"response:\", response)\n",
    "    \n",
    "def convert_cm_to_percentage(cm):\n",
    "    #Converts confusion matrix into label accurracy percentages\n",
    "    confusion_percentage_accurracies = []\n",
    "    for i in cm:\n",
    "        for j in i:\n",
    "            confusion_percentage_accurracies.append(j/int(sum(i)))\n",
    "\n",
    "\n",
    "    cm_size = int(math.sqrt(len(confusion_percentage_accurracies)))\n",
    "    length_to_split = [cm_size] * cm_size\n",
    "    iter_item = iter(confusion_percentage_accurracies)\n",
    "    confusion_percentage_array = [list(islice(iter_item, elem))\n",
    "            for elem in length_to_split]\n",
    "    \n",
    "    return confusion_percentage_array\n",
    "    \n",
    "def load_dataframe_to_bigquery(df, table_id):\n",
    "    \n",
    "    client = bigquery.Client()\n",
    "    #here we're saving a table for each model which we can union together later in sql if necessary\n",
    "    job_config = bigquery.LoadJobConfig(write_disposition=\"WRITE_TRUNCATE\") \n",
    "\n",
    "    job = client.load_table_from_dataframe(df, table_id, job_config=job_config)  # Make an API request.\n",
    "    job.result()  # Wait for the job to complete.\n",
    "\n",
    "    table = client.get_table(table_id)  # Make an API request.\n",
    "    print(f'Loaded {table.num_rows} rows and {len(table.schema)} columns to {table_id}')\n",
    "    \n",
    "    \n",
    "def create_batch_prediction_job_sample(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    model_resource_name: str,\n",
    "    job_display_name: str,\n",
    "    gcs_source: str,\n",
    "    gcs_destination: str,\n",
    "    sync: bool = True,\n",
    "):\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    my_model = aiplatform.Model(model_resource_name)\n",
    "\n",
    "    batch_prediction_job = my_model.batch_predict(\n",
    "        job_display_name=job_display_name,\n",
    "        gcs_source=gcs_source,\n",
    "        gcs_destination_prefix=gcs_destination,\n",
    "        sync=sync,\n",
    "    )\n",
    "\n",
    "    batch_prediction_job.wait()\n",
    "\n",
    "    print(batch_prediction_job.display_name)\n",
    "    print(batch_prediction_job.resource_name)\n",
    "    print(batch_prediction_job.state)\n",
    "    return batch_prediction_job\n",
    "\n",
    "def write_string_to_gcs_txt(string ,file_name, bucket_name):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(file_name)\n",
    "    blob.upload_from_string(string)\n",
    "    \n",
    "def upload_blob(source_file_name, destination_blob_name, bucket_name):\n",
    "  \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "  storage_client = storage.Client()\n",
    "  bucket = storage_client.get_bucket(bucket_name)\n",
    "  blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "  blob.upload_from_filename(source_file_name)\n",
    "\n",
    "  print('File {} uploaded to {}.'.format(\n",
    "      source_file_name,\n",
    "      destination_blob_name))\n",
    "    \n",
    "def list_blobs(bucket_name , prefix = None):\n",
    "    \"\"\"Lists all the blobs in the bucket.\"\"\"\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Note: Client.list_blobs requires at least package version 1.17.0.\n",
    "    blobs = storage_client.list_blobs(bucket_name, prefix = prefix)\n",
    "\n",
    "    # Note: The call returns a response only when the iterator is consumed.\n",
    "    for blob in blobs:\n",
    "        print(blob.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8737c0b3-0249-4409-ba96-bd89e66ae912",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Create Vertex AI TextDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c218034-59e1-4ecc-8e99-b05eb8a1c801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a TextDataset in VertexAI from a predefined csv file stored in gcs \n",
    "if create_dataset == True:\n",
    "    create_and_import_text_dataset_from_bigquery(filename,gcp_project,location,gcs_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdedfc8-5c61-42f6-896a-05d9684708e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Train Vertex AI Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91e1310-bc74-4d36-8cbc-76a9442b37f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starts an AutoMLTextTrainingJob in VertexAI from a predefined TextDataset\n",
    "if create_model == True:\n",
    "    model = create_training_pipeline_text_sentiment_analysis_sample(\n",
    "        project= gcp_project,\n",
    "        display_name = 'dataset'+ model_display_name,\n",
    "        dataset_id = dataset_id,\n",
    "        location= location,\n",
    "        model_display_name = model_display_name,\n",
    "        sentiment_max = 2\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09714d2a-1054-48b3-8550-3714d3ce509a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f529ea56-54a7-4802-993d-7ec16db55e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetches model evaluations from a trained AutoMLTextModel given a model_parent\n",
    "model_client = aiplatform.gapic.ModelServiceClient(client_options={'api_endpoint': f'{location}-aiplatform.googleapis.com'})\n",
    "list_eval = model_client.list_model_evaluations(parent=model_parent)\n",
    "\n",
    "for evaluation in list_eval:\n",
    "    eval_name = evaluation.name\n",
    "\n",
    "overall_eval = model_client.get_model_evaluation(name=eval_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc129c32-5079-4bae-88dd-1e25c9098120",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove hash to show model evaluations json output\n",
    "#overall_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91890338-9dad-452d-86c1-9715dd2847af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads metrics from model evaluations json output \n",
    "f1Score = overall_eval.metrics['f1Score']\n",
    "linearKappa = overall_eval.metrics['linearKappa']\n",
    "meanSquaredError = overall_eval.metrics['meanSquaredError']\n",
    "meanAbsoluteError = overall_eval.metrics['meanAbsoluteError']\n",
    "precision = overall_eval.metrics['precision']\n",
    "quadraticKappa = overall_eval.metrics['quadraticKappa']\n",
    "recall = overall_eval.metrics['recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413b85bb-5da6-491d-ac6a-2a71db6c443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Investigating the confusion matrix output\n",
    "\n",
    "#Here we can see the proto.marshal....MapComposite objects are iterable\n",
    "for i in overall_eval.metrics['confusionMatrix']:\n",
    "    print(overall_eval.metrics['confusionMatrix'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e794f07-c176-4a47-bafb-1ed30b39a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_percentage_array = convert_cm_to_percentage(overall_eval.metrics['confusionMatrix']['rows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f40c2-b38d-4667-bb56-eceaabdc0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates DataFrame of the confusion matrix\n",
    "confusion_matrix_df = pd.DataFrame(overall_eval.metrics['confusionMatrix']['rows'], columns = ['Negative_pred', 'Neutral_pred', 'Positive_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c769659-c41f-4278-a05e-e838bc096593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates DataFrame of the confusion matrix\n",
    "confusion_matrix_percentages_df = pd.DataFrame(confusion_percentage_array,columns = ['Negative_pred', 'Neutral_pred', 'Positive_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9927c25d-2d44-41f0-ae3d-07877f05fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_percentages_df.insert(loc=0, column='model_id', value=model_id)\n",
    "confusion_matrix_percentages_df.insert(loc=1, column='Sentiment_actuals', value=['Negative', 'Neutral', 'Positive'])\n",
    "\n",
    "confusion_matrix_df.insert(loc=0, column='model_id', value=model_id)\n",
    "confusion_matrix_df.insert(loc=1, column='Sentiment_actuals', value=['Negative', 'Neutral', 'Positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbac5f38-a14d-45a8-b8a6-45408aefa6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example confusion matrix output\n",
    "confusion_matrix_percentages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa500a23-7588-43ea-83e3-9f25e28ae9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example confusion matrix output\n",
    "confusion_matrix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b924e057-dcab-4412-96ef-463ec3414675",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Investigating gsc_source csv\n",
    "csv_data_df = pd.read_csv(gcs_source, header=None)\n",
    "csv_data_df.columns = ['Test_Train_Validation','Text','Sentiment','max_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19eb54ee-ae65-4847-9f8e-ff86bd893958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates sentiment_representation from csv\n",
    "sentiment_representation = list(csv_data_df.groupby(['Sentiment']).size())\n",
    "negative_representation = sentiment_representation[0]\n",
    "neutral_representation = sentiment_representation[1]\n",
    "positive_representation = sentiment_representation[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5417dfd2-8d01-4f96-b387-5181713c7933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates test/train split from csv\n",
    "no_test_items = list(csv_data_df.groupby(['Test_Train_Validation']).size())[0]\n",
    "no_train_items = list(csv_data_df.groupby(['Test_Train_Validation']).size())[1]\n",
    "no_val_items = list(csv_data_df.groupby(['Test_Train_Validation']).size())[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472a3ed9-c09b-475e-932c-eb0030915263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates DataFrame from evaluation metrics\n",
    "evaluation_metrics = [[model_id, no_test_items, no_train_items, no_val_items, f1Score, linearKappa, meanSquaredError, meanAbsoluteError, precision, quadraticKappa, recall]]\n",
    "evaluation_metric_cols = ['model_id','no_test_items', 'no_train_items', 'no_val_items', 'f1Score', 'linearKappa', 'meanSquaredError', 'meanAbsoluteError', 'precision', 'quadraticKappa', 'recall']\n",
    "evaluation_metrics_df = pd.DataFrame(evaluation_metrics, columns = evaluation_metric_cols)\n",
    "evaluation_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad08413-8048-468e-bd9e-7fbbab4bed65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f7ac25-5427-47b9-ba75-5179da2c7289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads DataFrames to BQ\n",
    "if load_evals_to_bq == True:\n",
    "    load_dataframe_to_bigquery(evaluation_metrics_df, table_id=f'{gcp_project}.{bq_dataset}.model_evaluation{model_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e43a9b-1945-42a1-8af0-850dfe3d2d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note, csv data is saved as this variable, see documentation https://cloud.google.com/vertex-ai/docs/text-data/sentiment-analysis/prepare-data for data prep input\n",
    "csv_data_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04227634-18cb-43b3-9bf6-701345058612",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads DataFrames to BQ\n",
    "if load_gcs_source_to_bq == True:\n",
    "    load_dataframe_to_bigquery(csv_data_df, table_id=f'{gcp_project}.{bq_dataset}.model_input_csv{model_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd7f41e-0410-4262-a63e-bb5eeca22058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads DataFrames to BQ\n",
    "if load_confusion_matrix_to_bq == True:\n",
    "    load_dataframe_to_bigquery(confusion_matrix_df, table_id=f'{gcp_project}.{bq_dataset}.confusion_matrix{model_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a45e922-fdbc-4467-8361-6861f84215f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads DataFrames to BQ\n",
    "if load_confusion_matrix_to_bq == True:\n",
    "    load_dataframe_to_bigquery(confusion_matrix_percentages_df, table_id=f'{gcp_project}.{bq_dataset}.confusion_matrix_percentage{model_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5968c04-0cfa-4f86-89e1-ca49d7b56875",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#additional code bits not yet used\n",
    "'''\n",
    "Corona_NLP_test = pd.read_csv('gs://mlai-nlp/Corona_NLP_test.csv', encoding='iso-8859-1')\n",
    "Corona_NLP_train = pd.read_csv('gs://mlai-nlp/Corona_NLP_train.csv', encoding='iso-8859-1')\n",
    "\n",
    "#Calculates number of test items\n",
    "no_test_items = int(confusion_matrix_df.values.sum())\n",
    "print('no_test_items:', no_test_items)\n",
    "\n",
    "get_model_evaluation_text_sentiment_analysis_sample(\n",
    "    project = gcp_project,\n",
    "    model_id = model_id,\n",
    "    evaluation_id = '4292050566529417216',\n",
    "    location = location,\n",
    "    api_endpoint = f\"{location}-aiplatform.googleapis.com\",\n",
    ")\n",
    "\n",
    "\n",
    "get_model_evaluation_slice_sample(\n",
    "    project = gcp_project,\n",
    "    model_id = model_id,\n",
    "    evaluation_id = '4292050566529417216',\n",
    "    location = location,\n",
    "    api_endpoint = f\"{location}-aiplatform.googleapis.com\",\n",
    "    slice_id = '',\n",
    ")\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda43b21-e2c7-4816-af72-e474ea898b08",
   "metadata": {},
   "source": [
    "## Batch Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa982e5e-e20a-462c-bf94-14a92b459592",
   "metadata": {},
   "source": [
    "# Steps\n",
    "\n",
    "* Create txt files for prediction, saved to EUW4 bucket location\n",
    "* Create input JSONL file containing txt file locations\n",
    "* Perform batch prediction\n",
    "* Read JSONL results from GCS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d58cb95-a5bc-4775-b943-82bb3fe0057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates inference Dataframe from csv\n",
    "inference_dataset = pd.read_csv(inference_dataset_source, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a08c793-ba75-4cb9-a8b5-88eead70fd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes elelments of inference_dataset to bucket as individual TXT files. JSON list then appends the individaul filenames to a list to later create a JSON input file\n",
    "create_inference_txt = True\n",
    "\n",
    "json_list = []\n",
    "\n",
    "if create_inference_txt == True:\n",
    "    for i in range(len(inference_dataset)):\n",
    "        write_string_to_gcs_txt(inference_dataset.iloc[i][0], f'inference-files/{todays_date}/{i}.txt',inference_bucket)\n",
    "        json_list.append({'content': f'gs://nlp-batch-prediction-test/inference-files/{todays_date}/{i}.txt', 'mimeType': 'text/plain'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6998914-dbab-4eb5-ae89-f8cb249c1e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates a JSON input file\n",
    "json_input_filename = 'output.jsonl'\n",
    "\n",
    "with open(json_input_filename, 'w') as outfile:\n",
    "    for entry in json_list: \n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df5377f-a4e3-4e0a-95bc-54db54f13179",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uploads a JSON input file to GCS\n",
    "upload_blob(json_input_filename, f'cleaned_data/{json_input_filename}', source_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958892aa-7ee1-4ce1-a53b-218f88a3b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input = f'gs://mlai-nlp/cleaned_data/{json_input_filename}'\n",
    "\n",
    "# Perform batch prediction\n",
    "if preform_batch_prediction == True:\n",
    "    create_batch_prediction_job_sample(\n",
    "        project = gcp_project,\n",
    "        location = location,\n",
    "        model_resource_name = model_parent,\n",
    "        job_display_name = 'test_predict',\n",
    "        gcs_source = batch_input,\n",
    "        gcs_destination = 'gs://mlai-nlp/cleaned_data/batch_prediction/results',\n",
    "        sync = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21696093-a20a-4e3c-b349-c9446c4c01c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Searches bucket of prediction results, appends blobs to blob_list\n",
    "blobs = storage.Client().list_blobs(source_bucket, prefix = 'cleaned_data/batch_prediction/results/')\n",
    "\n",
    "blob_list = []\n",
    "for i in blobs:\n",
    "    blob_list.append(i.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74f3a4a-c501-4e13-8602-17d8b4d75715",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finds the latest batch_prediction\n",
    "blob_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb336244-dad8-4368-b593-c6fdb498b8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finds the latest batch_prediction\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.bucket(source_bucket)\n",
    "blob = bucket.blob(blob_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4e06b2-3d99-4d7c-819f-f501dc4f820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reads the batch_prediction\n",
    "with blob.open(\"r\") as file:\n",
    "    batch_prediction_output = file.read()\n",
    "    print(batch_prediction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa382d03-d022-4d69-975e-7383bf49fb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterates through batch prediction to append the text index and predictions \n",
    "batch_prediction_output_list = batch_prediction_output.split('\\n')\n",
    "txt_index = []\n",
    "prediction = []\n",
    "for i in range(len(batch_prediction_output_list)-1):\n",
    "    txt_index.append(batch_prediction_output_list[i].split('.txt')[0][-1])\n",
    "    prediction.append(batch_prediction_output_list[i].split(\":\")[-1][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c99072-5112-4361-bd9d-d56f5aa062c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates batch prediction dataframe\n",
    "batch_predict_df = pd.DataFrame({'txt_index': txt_index , 'prediction' : prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71beb47f-1ccd-4277-955c-811dfc66ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merges batch prediction dataframe to original inference dataset based off the indexing. This creates a final batch prediciton dataframe consisting of the original text and the predictionss\n",
    "batch_predict_df = batch_predict_df.sort_values('txt_index')\n",
    "batch_predict_df = batch_predict_df.reset_index()\n",
    "inference_dataset = inference_dataset.rename(columns={0: \"Text\"})['Text']\n",
    "batch_predict_final_df = pd.concat([inference_dataset,batch_predict_df['prediction']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b1662e-d36d-4693-b71b-aed36d9f16e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_predict_final_df = pd.concat([inference_dataset,batch_predict_df['prediction']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c021521b-1b8d-461c-9e70-ad11a9b35cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_predict_final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190ce831-c8b2-459c-bee9-e181e10e80a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads DataFrames to BQ\n",
    "if load_batch_prediction_to_bq == True:\n",
    "    load_dataframe_to_bigquery(batch_predict_final_df, table_id=f'{gcp_project}.{bq_dataset}.batch_prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d28dc-18df-466c-97fe-6446b2b89d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
